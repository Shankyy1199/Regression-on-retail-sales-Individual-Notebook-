{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shankyy1199/Regression-on-retail-sales-Individual-Notebook-/blob/main/Regression_Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Sales Prediction : Predicting sales of a major store chain Rossmann\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "`# This is formatted as code`\n",
        "```\n",
        "\n",
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Team\n",
        "##### **Team Member 1 -** Shashank Chavan (stchavan7038@gmail.com)\n",
        "##### **Team Member 2 -**\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two datasets, Rossmann store dataset and the store data set. Rossmann store dataset contains 1017209 rows and 9 columns without duplicate data and null values.\n",
        "Store dataset contains 1115 rows and 10 columns without duplicate data and some null values in columns CompetitionDistance, CompetitionOpenSinceMonth,CompetitionOpenSinceYear, Promo2SinceWeek, Promo2SinceYear, PromoInterval.\n",
        "After treating the null values and doing feature engineering we got below results.  \n",
        "\n",
        "In this project, a Random Forest machine learning model has been selected as the final model for predicting sales for the next 6 weeks. Here's a brief summary of the key findings and the project's status:\n",
        "\n",
        "Model Selection:\n",
        "\n",
        "The Random Forest machine learning model has been chosen as the final predictive model due to its outstanding performance.\n",
        "The model achieved a high training accuracy of 99.63%, indicating a strong fit to the training data.\n",
        "Testing Accuracy:\n",
        "\n",
        "The model's test accuracy is 97.47%, which suggests that it performs exceptionally well on unseen data, demonstrating its reliability for future predictions.\n",
        "\n",
        "Mean Squared Error (MSE):\n",
        "\n",
        "The mean squared error is impressively low, with a value of 0.0046, indicating that the model's predictions are very close to the actual sales values.\n",
        "Project Objective:\n",
        "\n",
        "The primary goal of this project is to build a predictive model capable of forecasting sales for the next 6 weeks for Rossmann stores.\n",
        "By achieving high accuracy and low mean squared error, the Random Forest model has demonstrated its potential to provide accurate sales predictions, which can be valuable for optimizing inventory, staffing, and other operational decisions for the Rossmann stores in the future."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rossmann operates a network of more than 3,000 drug stores across seven European countries. At present, store managers at Rossmann are responsible for forecasting their daily sales for a period of up to six weeks in advance. These sales predictions are affected by a multitude of factors, such as promotional activities, competitive factors, school and public holidays, seasonal patterns, and the specific location of each store. Given the diverse set of conditions that each store manager faces, the accuracy of these sales predictions can vary significantly.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import pylab\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bPE_pyEsvC-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Rossmanm store dataset\n",
        "File_directory = '/content/drive/MyDrive/Colab Notebooks/Regression/'\n",
        "rossmann_df = pd.read_csv(File_directory + 'Rossmann Stores Data.csv')\n",
        "store_df = pd.read_csv(File_directory + 'store.csv')"
      ],
      "metadata": {
        "id": "Di-X0aOkvR9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "rossmann_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset random sample\n",
        "rossmann_df.sample(5)"
      ],
      "metadata": {
        "id": "iJdEvVlGyYrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset last rows\n",
        "rossmann_df.tail()"
      ],
      "metadata": {
        "id": "ukvWrRp1yrCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.head()"
      ],
      "metadata": {
        "id": "0Ff3EGWUzoxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.sample(5)"
      ],
      "metadata": {
        "id": "ZeKMCf2Bz1s4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.tail()"
      ],
      "metadata": {
        "id": "0y0yZLrl0HFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "rossmann_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.shape"
      ],
      "metadata": {
        "id": "m-4i-awK0StR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "rossmann_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.info()"
      ],
      "metadata": {
        "id": "x8TJepeh0fgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(rossmann_df[rossmann_df.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(store_df[store_df.duplicated()])"
      ],
      "metadata": {
        "id": "_BOaHsM21Zj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "rossmann_df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.isnull().sum()"
      ],
      "metadata": {
        "id": "IeAFvc2D11nE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many Nan values in columns - **'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear, Promointerval', 'Promo2sinceWeek' and 'Promo2sinceYear'**. Also **CompetitionDistance** has only 3 null values."
      ],
      "metadata": {
        "id": "sGf7r7x_fNtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.rcParams['figure.figsize']=(7,4)\n",
        "sns.heatmap(store_df.isnull().T, cbar=False)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two datasets, Rossmann store dataset and the store data set. Rossmann store dataset contains 1017209 rows and 9 columns without duplicate data and null values.\n",
        "Store dataset contains 1115 rows and 10 columns without duplicate data and some null values in columns CompetitionDistance, CompetitionOpenSinceMonth,CompetitionOpenSinceYear, Promo2SinceWeek, Promo2SinceYear, PromoInterval  "
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "rossmann_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.columns"
      ],
      "metadata": {
        "id": "qUYaz-fy4mlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "rossmann_df.describe(include='all').T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.describe(include='all').T"
      ],
      "metadata": {
        "id": "zicqSUQX5V-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### <b>Rossmann Stores Data.csv </b> - historical data including Sales\n",
        "### <b>store.csv </b> - supplemental information about the stores\n",
        "\n",
        "\n",
        "### <b><u>Data fields</u></b>\n",
        "### Most of the fields are self-explanatory. The following are descriptions for those that aren't.\n",
        "\n",
        "* #### Id - an unique Id\n",
        "* #### Store - a unique Id for each store\n",
        "* #### Sales - the turnover for any given day (this is what you are predicting)\n",
        "* #### Customers - the number of customers on a given day\n",
        "* #### Open - an indicator for whether the store was open: 0 = closed, 1 = open\n",
        "* #### StateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None\n",
        "* #### SchoolHoliday - indicates if the (Store, Date) was affected by the closure of public schools\n",
        "* #### StoreType - differentiates between 4 different store models: a, b, c, d\n",
        "* #### Assortment - describes an assortment level: a = basic, b = extra, c = extended\n",
        "* #### CompetitionDistance - distance in meters to the nearest competitor store\n",
        "* #### CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened\n",
        "* #### Promo - indicates whether a store is running a promo on that day\n",
        "* #### Promo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating\n",
        "* #### Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2\n",
        "* #### PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in rossmann_df.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",rossmann_df[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#let us see the null rows present the competition distance column\n",
        "store_df[pd.isnull(store_df.CompetitionDistance)]"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, we can fill these three values with many ways such as 0 or mean or mode or median. We decided to fill with it Mean."
      ],
      "metadata": {
        "id": "YAUurOpzfbVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Replacing Nan values in CompetitionDistance with mean distance.\n",
        "store_df['CompetitionDistance'].fillna(store_df['CompetitionDistance'].mean(), inplace = True)"
      ],
      "metadata": {
        "id": "FwvsR8GV9Oq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.isnull().sum()"
      ],
      "metadata": {
        "id": "mTmwVJh3koIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As CompetitionOpenSinceMonth, CompetitionOpenSinceYear, Promo2SinceWeek Promo2SinceYear, PromoInterval contains null values and we we do not have much information about them, we will fill it with 0 and PromoInterval with none as it is object type.                "
      ],
      "metadata": {
        "id": "8AExImjvnCaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for replacing Nan values with 0 for int datatype columns and none for obj datatype column.\n",
        "\n",
        "store_new = store_df.copy()\n",
        "\n",
        "#Replacing Nan values with 0 in CompetitionOpenSinceMonth\n",
        "store_new['CompetitionOpenSinceMonth'] = store_new['CompetitionOpenSinceMonth'].fillna(0)\n",
        "\n",
        "#Replacing Nan values with 0 in CompetitionOpenSinceYear\n",
        "store_new['CompetitionOpenSinceYear'] = store_new['CompetitionOpenSinceYear'].fillna(0)\n",
        "\n",
        "#Replacing Nan values with 0 in Promo2SinceWeek\n",
        "store_new['Promo2SinceWeek'] = store_new['Promo2SinceWeek'].fillna(0)\n",
        "\n",
        "#Replacing Nan values with 0 in Promo2SinceYear\n",
        "store_new['Promo2SinceYear'] = store_new['Promo2SinceYear'].fillna(0)\n",
        "\n",
        "#Replacing Nan values with None in PromoInterval\n",
        "store_new['PromoInterval'] = store_new['PromoInterval'].fillna('None')\n",
        "\n",
        "#Let us check the null values after imputation\n",
        "store_new.isnull().sum()\n"
      ],
      "metadata": {
        "id": "QV3CmZTxlUAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us convert the current datatypes of the columns to the appropriate datatype"
      ],
      "metadata": {
        "id": "H-mTRr_LupXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for changing StateHoliday dtype from object to int.\n",
        "rossmann_new = rossmann_df.copy()\n",
        "#Replacing 0 representing no holiday with 0 and a, b, c with 1 representing different holidays\n",
        "rossmann_new[\"StateHoliday\"] = rossmann_df[\"StateHoliday\"].map({0: 0, \"0\": 0, \"a\": 1, \"b\": 1, \"c\": 1})\n",
        "rossmann_new['StateHoliday'] = rossmann_new['StateHoliday'].astype(int, copy=False)\n",
        "rossmann_new[['StateHoliday']].value_counts()\n"
      ],
      "metadata": {
        "id": "ywrnLVBAuPuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#code for changing Date dtype from object to datetime.\n",
        "rossmann_new['Date'] = pd.to_datetime(rossmann_new['Date'], format= '%Y-%m-%d')"
      ],
      "metadata": {
        "id": "KOKgVZcFwqPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#code for changing CompetitionOpenSinceYear, CompetitionOpenSinceMonth and Promo2sinceYear dtype from object to int.\n",
        "store_new['CompetitionOpenSinceYear']= store_new['CompetitionOpenSinceYear'].astype(int)\n",
        "store_new['CompetitionOpenSinceMonth'] = store_new['CompetitionOpenSinceMonth'].astype(int)\n",
        "store_new['Promo2SinceYear']= store_new['Promo2SinceYear'].astype(int)"
      ],
      "metadata": {
        "id": "3hb9AnvO6z28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#code for changing CompetitionDistance and Promo2SinceWeek dtype from object to int.\n",
        "store_new['CompetitionDistance']= store_new['CompetitionDistance'].astype(int)\n",
        "store_new['Promo2SinceWeek']= store_new['Promo2SinceWeek'].astype(int)"
      ],
      "metadata": {
        "id": "2KQ2B9bR7EQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_new.dtypes"
      ],
      "metadata": {
        "id": "f530g2PP7JrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge the Rossmann_new and Store_new csv by column 'Store' as it is common in both dataframes"
      ],
      "metadata": {
        "id": "mZX_VxwU-vZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rossmann_store = pd.merge(rossmann_new, store_new, on='Store', how='left')\n",
        "rossmann_store.sample(5)"
      ],
      "metadata": {
        "id": "-76EXy4P-6R4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gives the month as January=1, December=12 from Date column\n",
        "rossmann_store['CompetitionOpenSinceMonth'] = pd.DatetimeIndex(rossmann_store['Date']).month"
      ],
      "metadata": {
        "id": "RoIAMvc8_d-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 Does promotion have positive effect on sales?\n",
        "ax=plt.rcParams['figure.figsize'] = 5,3\n",
        "sns.set_style(\"ticks\")\n",
        "#Code for poltting bar plot\n",
        "ax = sns.barplot(data=rossmann_store, x='Promo', y='Sales', palette='rocket')\n",
        "ax.set_title(\"Sales Vs Promo\",fontsize=8,fontweight='bold')\n",
        "ax.set_xlabel('Promo', fontsize=7,fontweight='bold')\n",
        "ax.set_ylabel('Sales',fontsize=7,fontweight='bold')\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "gAXb-SoBstsa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Barplot between promo and Sales shows the effect of promotion on Sales. Here 0 represents the store which didnt opt for promotion and 1 represents for stores who opt for promotion. Those store who did promotions their sales are high as compared to stores who didn't took promotion."
      ],
      "metadata": {
        "id": "dCEiQYCNoTcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "sp0IlZifq9CW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 Does promotion 2 have positive effect on sales?\n",
        "ax=plt.rcParams['figure.figsize'] = 5,3\n",
        "sns.set_style(\"ticks\")\n",
        "ax = sns.barplot(data=rossmann_store, x='Promo2', y='Sales', palette='rocket')\n",
        "ax.set_title(\"Sales Vs Promo 2\",fontsize=8,fontweight='bold')\n",
        "ax.set_xlabel('Promo2', fontsize=7,fontweight='bold')\n",
        "ax.set_ylabel('Sales',fontsize=7,fontweight='bold')"
      ],
      "metadata": {
        "id": "_v6w6TkCFBJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Barplot between promo2 and Sales shows the effect of consecutive promotion on Sales. Here 0 represents the store which didnt opt for promotion and 1 represents for stores who opt for promotion. There is not much effect on sales after promo2"
      ],
      "metadata": {
        "id": "cUK3k-g3opsZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 Does state holidays affect on overall sales\n",
        "ax=plt.rcParams['figure.figsize'] = 5,3\n",
        "sns.set_style(\"ticks\")\n",
        "ax = sns.barplot(data=rossmann_store, x='StateHoliday', y='Sales', palette='rocket')\n",
        "ax.set_title(\"Sales Vs State Holiday\",fontsize=8,fontweight='bold')\n",
        "ax.set_xlabel('StateHoliday', fontsize=7,fontweight='bold')\n",
        "ax.set_ylabel('Sales',fontsize=7,fontweight='bold')"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On holidays the sales were quite low as compare to the working days as the most of the stores were closed."
      ],
      "metadata": {
        "id": "lCdW59ErrKyT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 Does school holiday affects the overall sales\n",
        "ax=plt.rcParams['figure.figsize'] = 5,3\n",
        "sns.set_style(\"ticks\")\n",
        "ax = sns.barplot(data=rossmann_store, x='SchoolHoliday', y='Sales', palette='rocket')\n",
        "ax.set_title(\"Sales Vs School Holiday\",fontsize=8,fontweight='bold')\n",
        "ax.set_xlabel('SchoolHoliday', fontsize=7,fontweight='bold')\n",
        "ax.set_ylabel('Sales',fontsize=7,fontweight='bold')"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "But it is interesting to note that the number of stores opened during School Holidays were more than that were opened during State Holidays.\n",
        "Another important thing to note is that the stores which were opened during School holidays had more sales than normal."
      ],
      "metadata": {
        "id": "J8t7CszwsMNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "_8wwURCEuBCl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here a, b and c represents\n",
        "\n",
        "1. a means basic things\n",
        "2. b means extra things\n",
        "3. c means extended things so the highest variety of products."
      ],
      "metadata": {
        "id": "XL7KHohcuHhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 What was the sales with repective different assortments\n",
        "ax=plt.rcParams['figure.figsize'] = 5,3\n",
        "sns.set_style(\"ticks\")\n",
        "ax = sns.barplot(data=rossmann_store, x='Assortment', y='Sales', palette='rocket')\n",
        "ax.set_title(\"Sales Vs Assortments\",fontsize=8,fontweight='bold')\n",
        "ax.set_xlabel('Assortment', fontsize=7,fontweight='bold')\n",
        "ax.set_ylabel('Sales',fontsize=7,fontweight='bold')"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here as we can observed that assortment b had most of the sales followed by the c. Assortment a had the lowest sale may be due to the reason less varities."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 What was the trend of sales in different months of year with and without promotions?\n",
        "ax=plt.rcParams['figure.figsize'] = 12,5\n",
        "sns.set_style(\"ticks\")\n",
        "ax = sns.pointplot(data=rossmann_store, x='CompetitionOpenSinceMonth', y='Sales', hue = 'Promo')\n",
        "ax.set_title(\"Sales Vs Competition Open Since Month\",fontsize=8,fontweight='bold')\n",
        "ax.set_xlabel('Competition Open Since Month', fontsize=7,fontweight='bold')\n",
        "ax.set_ylabel('Sales',fontsize=7,fontweight='bold')"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The line graph shows the trend of sales partitions on the condition that promotion were running or not"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot between Competition open since month and Sales explains the sales data in each month of a year. This data shows that sales after month november increases drastically both with promotion and without promotion although the promotion lead to increase the sales by almost 2 fold. This is very clear that in December month due to Christmas Eve and New year celebration everone is buying. So sales of Rossmann store is very high in December."
      ],
      "metadata": {
        "id": "P0VBnqp6wfAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 What was the trend of sales in different years with and without promotions?\n",
        "ax=plt.rcParams['figure.figsize'] = 17,5\n",
        "sns.set_style(\"ticks\")\n",
        "ax = sns.pointplot(data=rossmann_store, x='CompetitionOpenSinceYear', y='Sales',hue = 'Promo')\n",
        "ax.set_title(\"Sales Vs CompetitionOpenSinceYear\",fontsize=8,fontweight='bold')\n",
        "ax.set_xlabel('Competition Open Since Year', fontsize=7,fontweight='bold')\n",
        "ax.set_ylabel('Sales',fontsize=7,fontweight='bold')"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the Plot we can tell that Sales are high during the year 1900, as there are very few store were operated of Rossmann so there is less competition and sales are high. But as year pass on number of stores increased that means competition also increased and this leads to decline in the sales."
      ],
      "metadata": {
        "id": "YxzB83Nlxku3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 What was the trend of sales after different countinuing the promotion promotions?\n",
        "ax=plt.rcParams['figure.figsize'] = 12,5\n",
        "sns.set_style(\"ticks\")\n",
        "ax = sns.pointplot(data=rossmann_store, x='Promo2SinceYear', y='Sales')\n",
        "ax.set_title(\"Sales Vs Promo2SinceYear\",fontsize=8,fontweight='bold')\n",
        "ax.set_xlabel('Promo2 Since Year', fontsize=7,fontweight='bold')\n",
        "ax.set_ylabel('Sales',fontsize=7,fontweight='bold')"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot between Sales and promo2 since year shows that effect of sales of stores which continue their promotion. This data is available from year 2009 to 2015. Promo2 has very good effect on sales but in year 2013 sales be minimum and also in year 2012 and 2015 sales are very low."
      ],
      "metadata": {
        "id": "IOr5DPhvyQAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 What was the trend of sales in different days of week with and without promotions?\n",
        "ax=plt.rcParams['figure.figsize'] = 12,5\n",
        "sns.set_style(\"ticks\")\n",
        "ax = sns.pointplot(data=rossmann_store, x='DayOfWeek', y='Sales', hue = 'Promo')\n",
        "ax.set_title(\"Sales Vs DayOfWeek\",fontsize=8,fontweight='bold')\n",
        "ax.set_xlabel('Day of Week', fontsize=7,fontweight='bold')\n",
        "ax.set_ylabel('Sales',fontsize=7,fontweight='bold')"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot between Sales and Days of week shows that maximum sales is on Monday with promotion it was more than normal and sales gradually decreasing to 6th day of week i.e. on Saturday. It also shows that sales on Sunday is almost near to zero as on sunday maximum stores are closed. Also no promotion were carry out on saturdays."
      ],
      "metadata": {
        "id": "UqA64cRMzs1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#What was the number of stores, customers, sales and average competition distance for different store types?\n",
        "Store_counts = rossmann_store.groupby('StoreType',as_index=False).agg({'Store':'count', 'Customers':'sum', 'Sales':'sum', 'CompetitionDistance':'mean'})\n",
        "Store_counts"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "sns.set(font_scale=1.3)\n",
        "sns.set_style(\"whitegrid\")\n",
        "fig, axarr = plt.subplots(2,2, figsize=(15, 10))\n",
        "#Code for store count bar graph\n",
        "a = sns.barplot(data=Store_counts, x='StoreType', y='Store', ax=axarr[0,0], palette='rocket')\n",
        "a.set_title(\"Number of stores per store type\",fontsize=10,fontweight='bold')\n",
        "a.set_xlabel('Store Type', fontsize=10)\n",
        "a.set_ylabel('Number of stores',fontsize=10)\n",
        "\n",
        "#Code for store customer count bar graph\n",
        "b = sns.barplot(data=Store_counts, x='StoreType', y='Customers', ax=axarr[0,1], palette='rocket')\n",
        "b.set_title(\"Number of customers per store type\",fontsize=10,fontweight='bold')\n",
        "b.set_xlabel('Store Type',fontsize=10)\n",
        "b.set_ylabel('Number of customers',fontsize=10)\n",
        "\n",
        "#Code for store sales bar graph\n",
        "c = sns.barplot(data=Store_counts, x='StoreType', y='Sales', ax=axarr[1,0], palette='rocket')\n",
        "c.set_title(\"Amount of sale per store type\",fontsize=10,fontweight='bold')\n",
        "c.set_xlabel('Store Type', fontsize=10)\n",
        "c.set_ylabel('Amount of Sale',fontsize=10)\n",
        "\n",
        "#Code for average distance of competitor bar graph\n",
        "d = sns.barplot(data=Store_counts, x='StoreType', y='CompetitionDistance', ax=axarr[1,1], palette='rocket')\n",
        "d.set_title(\"Average distance of competative store\",fontsize=10,fontweight='bold')\n",
        "d.set_xlabel('Store Type',fontsize=10)\n",
        "d.set_ylabel('Distance of competative store',fontsize=10)"
      ],
      "metadata": {
        "id": "C4XLv24yOgC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The storetype A has the highest number of branches,sales and customers from the 4 different storetypes.\n",
        "\n",
        "The average diastance of competitor were less for b followed by the c and then a. The average competitor distance for d was the most.\n"
      ],
      "metadata": {
        "id": "rV-J5v-009DZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#What was the distribution of assortments in diffrent store types?\n",
        "sns.set_style(\"whitegrid\")\n",
        "fig.set_size_inches(11, 7)\n",
        "store_type=sns.countplot(x='StoreType',hue='Assortment', data=rossmann_store, palette=\"inferno\")\n",
        "store_type.set_title(\"Count of Assortments in different store type\",fontsize=10,fontweight='bold')\n",
        "store_type.set_xlabel('Store Type',fontsize=10)\n",
        "store_type.set_ylabel('Count of assortments',fontsize=10)"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly observe that most of the stores have either assortment type a or assortment type c."
      ],
      "metadata": {
        "id": "3_fkDodU2kdY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = ['DayOfWeek', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'Promo2SinceWeek',\n",
        "                    'CompetitionDistance','CompetitionOpenSinceMonth','CompetitionOpenSinceYear',\n",
        "                    'Promo2','Promo2SinceWeek','Promo2SinceYear']"
      ],
      "metadata": {
        "id": "Z1xglz7qJB2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#correlation heatmap\n",
        "plt.figure(figsize=(18,8))\n",
        "corr_heat = rossmann_store.corr().round(4)\n",
        "sns.heatmap(abs(corr_heat), annot=True, cmap='coolwarm')"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####  What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are strong correation between customers and open with sales  "
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Correlation between sales and numerical features"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us check the individual correlation of different features with over all sales\n",
        "numeric_features1 = [ 'Customers', 'Promo', 'StateHoliday', 'SchoolHoliday', 'Promo2SinceWeek',\n",
        "                    'CompetitionDistance','CompetitionOpenSinceMonth','CompetitionOpenSinceYear','DayOfWeek',\n",
        "                    'Promo2','Promo2SinceWeek','Promo2SinceYear']"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for plotting scatter plot with correlation line\n",
        "for col in numeric_features1[0:-1]:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = rossmann_store[col]\n",
        "    label = rossmann_store['Sales']\n",
        "    correlation = feature.corr(label)\n",
        "    plt.scatter(x=feature, y=label)\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Sales')\n",
        "    ax.set_title('Sales vs ' + col + '- correlation: ' + str(correlation))\n",
        "    z = np.polyfit(rossmann_store[col], rossmann_store['Sales'], 1)\n",
        "    y_hat = np.poly1d(z)(rossmann_store[col])\n",
        "\n",
        "    plt.plot(rossmann_store[col], y_hat, \"r--\", lw=1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2XyIE5bnf9_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us check the distribution of columns"
      ],
      "metadata": {
        "id": "nQD_fixOh7bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = [ 'Store','Customers', 'Promo','Sales','StateHoliday', 'SchoolHoliday', 'Promo2SinceWeek',\n",
        "                    'CompetitionDistance','CompetitionOpenSinceMonth','CompetitionOpenSinceYear','DayOfWeek',\n",
        "                    'Promo2','Promo2SinceWeek','Promo2SinceYear']"
      ],
      "metadata": {
        "id": "2q_qA7GDjFn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#A bar plot for each numerical feature count\n",
        "\n",
        "for col in numeric_features[0:]:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = rossmann_store[col]\n",
        "    feature.hist(bins=50, ax = ax)\n",
        "    ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "    ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)\n",
        "    ax.set_title(col)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1Fal-84kh6n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution of competition distance data\n",
        "plt.figure(figsize=(7,7))\n",
        "sns.distplot(rossmann_store['CompetitionDistance'],color=\"r\")"
      ],
      "metadata": {
        "id": "mU0BR6puiogK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Competition distance data is bit right-skewed so we decided to transform it."
      ],
      "metadata": {
        "id": "IMCK9JUOjSFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us do Log transformation for Competition Distance\n",
        "rossmann_store['CompetitionDistance'] = np.log(rossmann_store['CompetitionDistance'])"
      ],
      "metadata": {
        "id": "v9oyupGjjNhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removes the rows conatining '-inf' from data\n",
        "rossmann_store.drop(rossmann_store[rossmann_store['CompetitionDistance'] == float(\"-inf\")].index,inplace=True)"
      ],
      "metadata": {
        "id": "z5R4W_x4j8ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution of competition distance data\n",
        "plt.figure(figsize=(7,7))\n",
        "sns.distplot(rossmann_store['CompetitionDistance'],color=\"r\")"
      ],
      "metadata": {
        "id": "N-XXwS8gjy4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us check the sales distribution"
      ],
      "metadata": {
        "id": "-ph1Gdn4kUGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution plot of Sales, as expected positively skewed\n",
        "plt.figure(figsize=(7,7))\n",
        "sns.distplot(rossmann_store['Sales'],color=\"y\")"
      ],
      "metadata": {
        "id": "cGn2NWzmkWAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sales data is bit right skewed so we decide to transform it."
      ],
      "metadata": {
        "id": "SX2-fPQoyBKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us do Log transformation for sales\n",
        "rossmann_store['Sales'] = np.log(rossmann_store['Sales'])"
      ],
      "metadata": {
        "id": "C2Nm2QZEmaN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rossmann_store.drop(rossmann_store[rossmann_store['Sales'] == float(\"-inf\")].index,inplace=True)"
      ],
      "metadata": {
        "id": "wAeV7mdUnePP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,7))\n",
        "sns.distplot(rossmann_store['Sales'],color=\"y\")"
      ],
      "metadata": {
        "id": "DdaGnDH5nSg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some feature in our data a right skewed including dependent variable so we decided to tranformed it with log trasformation as it is not that severe."
      ],
      "metadata": {
        "id": "ZYpcrljWlWpr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multicollinearity"
      ],
      "metadata": {
        "id": "75tHKH75qRQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code to find multicollinearity\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def calc_vif(X):\n",
        "\n",
        "    # Calculating VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return(vif)"
      ],
      "metadata": {
        "id": "6bdIGKJxqeVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(rossmann_store[[i for i in rossmann_store.describe().columns if i not in ['Sales']]])"
      ],
      "metadata": {
        "id": "MorZRlR3q2KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the VIF for Promo2 and Promo2SinceYear and open are too high, so drop them which has low correlation with dependent variable"
      ],
      "metadata": {
        "id": "JKs0Csh3uQjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#VIF scores after dropping the highly correlated variables\n",
        "calc_vif(rossmann_store[[i for i in rossmann_store.describe().columns if i not in ['Sales','Promo2SinceYear','Open']]])"
      ],
      "metadata": {
        "id": "D-5AV4GArxuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking outliers in sales\n",
        "plt.figure(figsize=(5, 6))\n",
        "x = sns.boxplot(rossmann_store['Sales'])\n",
        "plt.title('Boxplot For Sales Values')"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the high sales which leads to outlier could be the sell on the promotion day so let us not remove them and directly feed to our model."
      ],
      "metadata": {
        "id": "pvEwWJW7xNaE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we know that closed stores have 0 sales, let us check how many stores are closed"
      ],
      "metadata": {
        "id": "iogBFSWjbQLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#no of observations for closed stores with 0 sales\n",
        "(rossmann_store[rossmann_store.Open == 0]).shape"
      ],
      "metadata": {
        "id": "zsyRjYA7bHT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(rossmann_store[rossmann_store.Open != 0]).shape"
      ],
      "metadata": {
        "id": "xrx846r8by_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The stores which are closed and with zero sales\n",
        "rossmann_store[(rossmann_store.Open == 0) & (rossmann_store.Sales == 0)].count()[0]"
      ],
      "metadata": {
        "id": "JuT4e1PA4mW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us create new dataset by dropping closed stores with zero sale\n",
        "rossmann_store_new = rossmann_store.drop(rossmann_store[(rossmann_store.Open == 0) & (rossmann_store.Sales == 0)].index)"
      ],
      "metadata": {
        "id": "MxQs91gKx6qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "df_new = pd.get_dummies(rossmann_store_new,columns=['StoreType','Assortment','PromoInterval'])\n",
        "df_new.head(1)"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use get dummies from pandas which encodes categorical columns"
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining dependent variable\n",
        "y = 'Sales'\n",
        "#Defining independent variable\n",
        "X = list(df_new.columns.drop(['Promo2SinceYear','Date','Open','Sales']))"
      ],
      "metadata": {
        "id": "pyqsQWIWDUwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the data of dependent variables\n",
        "y = df_new[y].values\n",
        "\n",
        "# Create the data of independent variable\n",
        "X = df_new[X].values"
      ],
      "metadata": {
        "id": "wfF3nGyuEZiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "Zlb2JdX8EEBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the train test split\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ABfHBJC8DD6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data in train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 32 )"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Shape of train and test set\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "bcmX-opUF672"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "3zf9LQnRl8gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use 80% data in training and 20% data in testing."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing libraries for modeling\n",
        "from scipy.stats import zscore\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score as r2, mean_squared_error, mean_absolute_error\n",
        "import math\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "9QvkNI-Bb9RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us check the model fitting and prediction in linear regression without scaling the data"
      ],
      "metadata": {
        "id": "V1Q7RWxN2HU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting model to training data\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "MTUD2bovcUJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.coef_"
      ],
      "metadata": {
        "id": "B_fGXPPjdFJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.intercept_"
      ],
      "metadata": {
        "id": "Pb_BpbHqdM7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction on test data\n",
        "y_pred_test = reg.predict(X_test)"
      ],
      "metadata": {
        "id": "F7MGhnMMdRws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = reg.predict(X_train)"
      ],
      "metadata": {
        "id": "mIW6hzQVf4Ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training score\n",
        "train_score1 = reg.score(X_train, y_train)\n",
        "train_score1"
      ],
      "metadata": {
        "id": "0J6VwnXKGXqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test score\n",
        "test_score1 = reg.score(X_test, y_test)\n",
        "test_score1"
      ],
      "metadata": {
        "id": "6DO14q7hXfak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate metrics and print the results for test set\n",
        "#Mean Absolute Error or MAE\n",
        "MAE_test = round(mean_absolute_error(y_test,y_pred_test),6)\n",
        "#Mean Squared Error or MSE\n",
        "MSE_test = round(mean_squared_error(y_test,y_pred_test),6)\n",
        "#Root Mean Squared Error or RMSE\n",
        "RMSE_test = round(mean_squared_error(y_test,y_pred_test,squared=False),6)\n",
        "#R2\n",
        "R2_test = round(r2_score(y_test, y_pred_test),6)\n",
        "#Adjusted R2\n",
        "Adj_r2_test = round(1 - (1-r2_score(y_test, y_pred_test)) * (len(y_test)-1)/(len(y_test)-X_test.shape[1]-1),6)\n",
        "#printing test results\n",
        "print(f'The Mean Absolute Error for the validation set is {MAE_test}')\n",
        "print(f'The Mean Squared Error for the validation set is {MSE_test}')\n",
        "print(f'The Root Mean Squared Error for the validation set is {RMSE_test}')\n",
        "print(f'The R^2 for the validation set is {R2_test}')\n",
        "print(f'The Adjusted R^2 for the validation set is {Adj_r2_test}')"
      ],
      "metadata": {
        "id": "YQ0ePtHceR9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling the data using standard scaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use standard scaler to scale data as it transforms features by subtracting from the mean and dividing by the standard deviation. The resulting data will have a mean of 0 and a standard deviation of 1."
      ],
      "metadata": {
        "id": "DJhq-coVpSMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *** ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model to training data\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "KU8O9WqzQPaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.coef_"
      ],
      "metadata": {
        "id": "4BeBrlvbMP-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.intercept_"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction on test data\n",
        "y_pred_test = reg.predict(X_test)\n",
        "y_pred_test"
      ],
      "metadata": {
        "id": "Uz8rQdX3Pm9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "Kc5oP7gkM3o7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = reg.predict(X_train)\n",
        "y_pred_train"
      ],
      "metadata": {
        "id": "D6bW9CJUNDSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training score\n",
        "train_score2 = reg.score(X_train, y_train)\n",
        "train_score2"
      ],
      "metadata": {
        "id": "ryJCBpyIGsUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing score\n",
        "test_score2 = reg.score(X_test, y_test)\n",
        "test_score2"
      ],
      "metadata": {
        "id": "QXB_oycqZFM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "E3Hh55lbsWT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate metrics and print the results for test set\n",
        "#Mean Absolute Error or MAE\n",
        "MAE_test = round(mean_absolute_error(y_test,y_pred_test),6)\n",
        "#Mean Squared Error or MSE\n",
        "MSE_test = round(mean_squared_error(y_test,y_pred_test),6)\n",
        "#Root Mean Squared Error or RMSE\n",
        "RMSE_test = round(mean_squared_error(y_test,y_pred_test,squared=False),6)\n",
        "#R2\n",
        "R2_test = round(r2_score(y_test, y_pred_test),6)\n",
        "#Adjusted R2\n",
        "Adj_r2_test = round(1 - (1-r2_score(y_test, y_pred_test)) * (len(y_test)-1)/(len(y_test)-X_test.shape[1]-1),6)\n",
        "#printing test results\n",
        "print(f'The Mean Absolute Error for the validation set is {MAE_test}')\n",
        "print(f'The Mean Squared Error for the validation set is {MSE_test}')\n",
        "print(f'The Root Mean Squared Error for the validation set is {RMSE_test}')\n",
        "print(f'The R^2 for the validation set is {R2_test}')\n",
        "print(f'The Adjusted R^2 for the validation set is {Adj_r2_test}')"
      ],
      "metadata": {
        "id": "eDw1xolFRwN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lasso (L1 regularization)"
      ],
      "metadata": {
        "id": "GorRt23tdVnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#appying L1 regularisation with alpha 0.001\n",
        "lasso = Lasso(alpha = 0.001)"
      ],
      "metadata": {
        "id": "YW7YONQ_U0MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting model on training data\n",
        "lasso.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "YtoLuwayU_3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso.coef_"
      ],
      "metadata": {
        "id": "KteB986QfT1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction on test data\n",
        "y_pred_L = lasso.predict(X_test)"
      ],
      "metadata": {
        "id": "_Z70-tWhVDCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train score\n",
        "train_score3 = lasso.score(X_train, y_train)\n",
        "train_score3"
      ],
      "metadata": {
        "id": "_PpPt9auG9y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test score\n",
        "test_score3 = lasso.score(X_train, y_train)\n",
        "test_score3"
      ],
      "metadata": {
        "id": "dRjRbUlvG_fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataframe showing actual and predicted results\n",
        "pd.DataFrame(zip(y_test, y_pred_L), columns = ['actual', 'pred'])"
      ],
      "metadata": {
        "id": "mtiYPneFfAV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "F3xYrdQ2sTV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate metrics and print the results for test set\n",
        "#Mean Absolute Error or MAE\n",
        "MAE_test = round(mean_absolute_error(y_test,y_pred_L),6)\n",
        "#Mean Squared Error or MSE\n",
        "MSE_test = round(mean_squared_error(y_test,y_pred_L),6)\n",
        "#Root Mean Squared Error or RMSE\n",
        "RMSE_test = round(mean_squared_error(y_test,y_pred_L,squared=False),6)\n",
        "#R2\n",
        "R2_test = round(r2_score(y_test, y_pred_L),6)\n",
        "#Adjusted R2\n",
        "Adj_r2_test = round(1 - (1-r2_score(y_test, y_pred_L)) * (len(y_test)-1)/(len(y_test)-X_test.shape[1]-1),6)\n",
        "#printing test results\n",
        "print(f'The Mean Absolute Error for the validation set is {MAE_test}')\n",
        "print(f'The Mean Squared Error for the validation set is {MSE_test}')\n",
        "print(f'The Root Mean Squared Error for the validation set is {RMSE_test}')\n",
        "print(f'The R^2 for the validation set is {R2_test}')\n",
        "print(f'The Adjusted R^2 for the validation set is {Adj_r2_test}')"
      ],
      "metadata": {
        "id": "A15gPFVNgxpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "OUm7KbE0TPiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Cross validation (Takes time to run)\n",
        "#parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "#lasso = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=5)\n"
      ],
      "metadata": {
        "id": "J_nOx_52lrRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"The best fit alpha value is found out to be :\" ,lasso.best_params_)\n",
        "#print(\"\\nUsing \",lasso.best_params_, \" the negative mean squared error is: \", lasso.best_score_)"
      ],
      "metadata": {
        "id": "sH6ZjTeBmJKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best fit alpha value is found out to be : {'alpha': 1e-05}\n",
        "\n",
        "Using  {'alpha': 1e-05}  the negative mean squared error is:  -0.025594252130675704\n"
      ],
      "metadata": {
        "id": "dyRWnR-FoewR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#L1 regularisation after finding the best parameters using grid search CV\n",
        "lasso = Lasso(alpha=1e-05)\n",
        "lasso.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "9FHe75Rkn-_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction on training data\n",
        "y_pred_LCV = lasso.predict(X_test)"
      ],
      "metadata": {
        "id": "VG8iaJXFngWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training score\n",
        "train_score4 = lasso.score(X_train, y_train)\n",
        "train_score4"
      ],
      "metadata": {
        "id": "GkzMhV1rFsd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test score\n",
        "test_score4 = lasso.score(X_test, y_test)\n",
        "test_score4"
      ],
      "metadata": {
        "id": "vKyhYBYyaJhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "rSQmhOcqsQBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate metrics and print the results for test set\n",
        "#Mean Absolute Error or MAE\n",
        "MAE_test = round(mean_absolute_error(y_test,y_pred_LCV),6)\n",
        "#Mean Squared Error or MSE\n",
        "MSE_test = round(mean_squared_error(y_test,y_pred_LCV),6)\n",
        "#Root Mean Squared Error or RMSE\n",
        "RMSE_test = round(mean_squared_error(y_test,y_pred_LCV,squared=False),6)\n",
        "#R2\n",
        "R2_test = round(r2_score(y_test, y_pred_LCV),6)\n",
        "#Adjusted R2\n",
        "Adj_r2_test = round(1 - (1-r2_score(y_test, y_pred_LCV)) * (len(y_test)-1)/(len(y_test)-X_test.shape[1]-1),6)\n",
        "#printing test results\n",
        "print(f'The Mean Absolute Error for the validation set is {MAE_test}')\n",
        "print(f'The Mean Squared Error for the validation set is {MSE_test}')\n",
        "print(f'The Root Mean Squared Error for the validation set is {RMSE_test}')\n",
        "print(f'The R^2 for the validation set is {R2_test}')\n",
        "print(f'The Adjusted R^2 for the validation set is {Adj_r2_test}')"
      ],
      "metadata": {
        "id": "xItdfA9oo_h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ridge (L2 regularization)"
      ],
      "metadata": {
        "id": "4sHWrifkiUs7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#L2 regularisation using grid search and cross validation\n",
        "RidgeCV = Ridge()\n",
        "parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "RidgeCV = GridSearchCV(RidgeCV, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "RidgeCV.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "EG9qJlvbiXYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit alpha value is found out to be :\" ,RidgeCV.best_params_)\n",
        "print(\"\\nUsing \",RidgeCV.best_params_, \" the negative mean squared error is: \", RidgeCV.best_score_)"
      ],
      "metadata": {
        "id": "WTtH_tV2qVX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction on test data\n",
        "y_pred_RCV = RidgeCV.predict(X_test)"
      ],
      "metadata": {
        "id": "Kl0QOR3FjE51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate metrics and print the results for test set\n",
        "#Mean Absolute Error or MAE\n",
        "MAE_test = round(mean_absolute_error(y_test,y_pred_RCV),6)\n",
        "#Mean Squared Error or MSE\n",
        "MSE_test = round(mean_squared_error(y_test,y_pred_RCV),6)\n",
        "#Root Mean Squared Error or RMSE\n",
        "RMSE_test = round(mean_squared_error(y_test,y_pred_RCV,squared=False),6)\n",
        "#R2\n",
        "R2_test = round(r2_score(y_test, y_pred_RCV),6)\n",
        "#Adjusted R2\n",
        "Adj_r2_test = round(1 - (1-r2_score(y_test, y_pred_RCV)) * (len(y_test)-1)/(len(y_test)-X_test.shape[1]-1),6)\n",
        "#printing test results\n",
        "print(f'The Mean Absolute Error for the validation set is {MAE_test}')\n",
        "print(f'The Mean Squared Error for the validation set is {MSE_test}')\n",
        "print(f'The Root Mean Squared Error for the validation set is {RMSE_test}')\n",
        "print(f'The R^2 for the validation set is {R2_test}')\n",
        "print(f'The Adjusted R^2 for the validation set is {Adj_r2_test}')"
      ],
      "metadata": {
        "id": "X44eRKh2jfHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use grid search cv for hyperparameter tunning, it shows very small change in r2 score"
      ],
      "metadata": {
        "id": "cH10cLWLrtKR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og1MGoIrM-8L"
      },
      "source": [
        "### DECISION TREE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the decision tree model on training data\n",
        "decision_tree=DecisionTreeRegressor(max_depth=12)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "#Prediction on test data\n",
        "y_pred_dt = decision_tree.predict(X_test)\n",
        "y_train_dt = decision_tree.predict(X_train)"
      ],
      "metadata": {
        "id": "pf8tXP-ikbQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training score\n",
        "train_score5 = decision_tree.score(X_train,y_train)\n",
        "train_score5"
      ],
      "metadata": {
        "id": "0eMuXDyHk1Ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test score\n",
        "test_score5 = decision_tree.score(X_test,y_test)\n",
        "test_score5"
      ],
      "metadata": {
        "id": "jArGhgDeslvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataframe showing both the test data and predicted data\n",
        "decisiontree_Dataframe = pd.DataFrame(zip(y_test, y_pred_dt), columns = ['actual', 'pred'])\n",
        "decisiontree_Dataframe"
      ],
      "metadata": {
        "id": "hNaKQ_8TlgX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate metrics and print the results for test set\n",
        "#Mean Absolute Error or MAE\n",
        "MAE_test = round(mean_absolute_error(y_test,y_pred_dt),6)\n",
        "#Mean Squared Error or MSE\n",
        "MSE_test = round(mean_squared_error(y_test,y_pred_dt),6)\n",
        "#Root Mean Squared Error or RMSE\n",
        "RMSE_test = round(mean_squared_error(y_test,y_pred_dt,squared=False),6)\n",
        "#R2\n",
        "R2_test = round(r2_score(y_test, y_pred_dt),6)\n",
        "#Adjusted R2\n",
        "Adj_r2_test = round(1 - (1-r2_score(y_test, y_pred_dt)) * (len(y_test)-1)/(len(y_test)-X_test.shape[1]-1),6)\n",
        "#printing test results\n",
        "print(f'The Mean Absolute Error for the validation set is {MAE_test}')\n",
        "print(f'The Mean Squared Error for the validation set is {MSE_test}')\n",
        "print(f'The Root Mean Squared Error for the validation set is {RMSE_test}')\n",
        "print(f'The R^2 for the validation set is {R2_test}')\n",
        "print(f'The Adjusted R^2 for the validation set is {Adj_r2_test}')"
      ],
      "metadata": {
        "id": "ahdUenn_hout"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Takes time to run\n",
        "#params = {\n",
        "#          'max_depth':[4,8,12,16],\n",
        "#          'min_samples_split':[2,3,5,7],\n",
        "#          'min_samples_leaf':[6,8,10],\n",
        "#        }\n",
        "\n",
        "#grid = GridSearchCV(decision_tree, params, scoring='neg_mean_squared_error', cv=3)\n"
      ],
      "metadata": {
        "id": "EWf05KITxK0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#grid.best_params_\n",
        "#{'max_depth': 16, 'min_samples_leaf': 6, 'min_samples_split': 3}"
      ],
      "metadata": {
        "id": "unB6CrwsxX2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting model with best parameters after grid search Cv\n",
        "decision_tree = DecisionTreeRegressor(max_depth=16, min_samples_leaf= 6, min_samples_split= 3)\n",
        "decision_tree.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "MgnKYN0Ixe8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction on test data\n",
        "y_pred_dtCV = decision_tree.predict(X_test)"
      ],
      "metadata": {
        "id": "23TjhRMRxpM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_score6 = decision_tree.score(X_train, y_train)\n",
        "train_score6"
      ],
      "metadata": {
        "id": "VVOsPwMMxqpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_score6 = decision_tree.score(X_test, y_test)\n",
        "test_score6"
      ],
      "metadata": {
        "id": "rCpOVfYpxuEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataframe showing test data and predicted data\n",
        "decisiontree_Dataframe = pd.DataFrame(zip(y_test, y_pred_dtCV), columns = ['actual', 'pred'])\n",
        "decisiontree_Dataframe"
      ],
      "metadata": {
        "id": "V-ocZx4sxxI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "hXuY-dpvyyRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate metrics and print the results for test set\n",
        "#Mean Absolute Error or MAE\n",
        "MAE_test = round(mean_absolute_error(y_test,y_pred_dtCV),6)\n",
        "#Mean Squared Error or MSE\n",
        "MSE_test = round(mean_squared_error(y_test,y_pred_dtCV),6)\n",
        "#Root Mean Squared Error or RMSE\n",
        "RMSE_test = round(mean_squared_error(y_test,y_pred_dtCV,squared=False),6)\n",
        "#R2\n",
        "R2_test = round(r2_score(y_test, y_pred_dtCV),6)\n",
        "#Adjusted R2\n",
        "Adj_r2_test = round(1 - (1-r2_score(y_test, y_pred_dtCV)) * (len(y_test)-1)/(len(y_test)-X_test.shape[1]-1),6)\n",
        "#printing test results\n",
        "print(f'The Mean Absolute Error for the validation set is {MAE_test}')\n",
        "print(f'The Mean Squared Error for the validation set is {MSE_test}')\n",
        "print(f'The Root Mean Squared Error for the validation set is {RMSE_test}')\n",
        "print(f'The R^2 for the validation set is {R2_test}')\n",
        "print(f'The Adjusted R^2 for the validation set is {Adj_r2_test}')"
      ],
      "metadata": {
        "id": "DIuOXDn3x1F9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. ML Model - Random Forest"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting random forest model on training data\n",
        "RandomForest = RandomForestRegressor()\n",
        "RandomForest.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction on test data\n",
        "y_pred_RF = RandomForest.predict(X_test)"
      ],
      "metadata": {
        "id": "xsOD2Inv4Oh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training score\n",
        "train_score7 = RandomForest.score(X_train, y_train)\n",
        "train_score7"
      ],
      "metadata": {
        "id": "s1hhbOrRBdIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test score\n",
        "test_score7 = RandomForest.score(X_test, y_test)\n",
        "test_score7"
      ],
      "metadata": {
        "id": "3abGz5lyD9tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataframe showing test data and predicted data\n",
        "RandomForest_Dataframe = pd.DataFrame(zip(y_test, y_pred_RF), columns = ['actual', 'pred'])\n",
        "RandomForest_Dataframe"
      ],
      "metadata": {
        "id": "GHa3xt4_4r5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate metrics and print the results for test set\n",
        "#Mean Absolute Error or MAE\n",
        "MAE_test = round(mean_absolute_error(y_test,y_pred_RF),6)\n",
        "#Mean Squared Error or MSE\n",
        "MSE_test = round(mean_squared_error(y_test,y_pred_RF),6)\n",
        "#Root Mean Squared Error or RMSE\n",
        "RMSE_test = round(mean_squared_error(y_test,y_pred_RF,squared=False),6)\n",
        "#R2\n",
        "R2_test = round(r2_score(y_test, y_pred_RF),6)\n",
        "#Adjusted R2\n",
        "Adj_r2_test = round(1 - (1-r2_score(y_test, y_pred_RF)) * (len(y_test)-1)/(len(y_test)-X_test.shape[1]-1),6)\n",
        "#printing test results\n",
        "print(f'The Mean Absolute Error for the validation set is {MAE_test}')\n",
        "print(f'The Mean Squared Error for the validation set is {MSE_test}')\n",
        "print(f'The Root Mean Squared Error for the validation set is {RMSE_test}')\n",
        "print(f'The R^2 for the validation set is {R2_test}')\n",
        "print(f'The Adjusted R^2 for the validation set is {Adj_r2_test}')"
      ],
      "metadata": {
        "id": "GhK1ziCd43bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to consider the mean squared error as evalution metric for our model."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can observed from above the random forest ML model as final model as it gives us the maximum accuracy and minimum mean squared error. The training accuracy is 99.63% while the test accuracy is 97.47%."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import pickle\n",
        "#with open ('model_pickle','wb') as f:\n",
        " # pickle.dump(RandomForest, f)"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predict_price = joblib.load('final_model')"
      ],
      "metadata": {
        "id": "ExxSOO5rXpIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTqXBAg2F2HQ"
      },
      "source": [
        "## Conclusions from EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Promotion Impact:**\n",
        "\n",
        "Stores that opted for promotions (represented by 1) generally had higher sales compared to those that didn't (represented by 0).\n",
        "\n",
        "**Consecutive Promotion (Promo2):**\n",
        "\n",
        "There wasn't a significant effect on sales after Promo2 was introduced, indicating that this type of promotion may not have had a substantial impact.\n",
        "\n",
        "**Holiday Sales:**\n",
        "\n",
        "Sales were notably lower during holidays when many stores were closed.\n",
        "More stores were open during School Holidays compared to State Holidays.\n",
        "Stores open during School holidays had higher sales than on regular days.\n",
        "\n",
        "**Assortment Impact:**\n",
        "\n",
        "Assortment type B had the highest sales, followed by C, while assortment A had the lowest sales, possibly due to a limited variety of products.\n",
        "\n",
        "**Competition:**\n",
        "\n",
        "Sales increased significantly after November, especially with promotions, likely due to holiday shopping.\n",
        "December had exceptionally high sales, likely due to Christmas and New Year celebrations.\n",
        "\n",
        "**Sales Trends Over the Years:**\n",
        "\n",
        "Sales were high in the year 1900 when there were fewer Rossmann stores and less competition.\n",
        "As the number of stores increased over the years, competition grew, leading to a decline in sales.\n",
        "\n",
        "**Promo2 Effect Over Time:**\n",
        "\n",
        "Promo2 had a positive effect on sales overall, but there were dips in sales in 2012, 2013, and 2015, suggesting that other factors may have influenced sales during these years.\n",
        "\n",
        "**Sales by Day of the Week:**\n",
        "\n",
        "Monday had the highest sales, with promotions increasing sales further.\n",
        "Sales gradually decreased throughout the week, with the lowest sales on Saturday and almost no sales on Sunday when many stores were closed.\n",
        "\n",
        "**Store Types:**\n",
        "\n",
        "Store type A had the highest number of branches, sales, and customers among the four different store types.\n",
        "\n",
        "**Competitor Distance:**\n",
        "\n",
        "Store type B had the shortest average competitor distance, followed by C and A. Store type D had the longest competitor distance.\n",
        "\n",
        "**Assortment Types:**\n",
        "\n",
        "Assortment types A and C were the most common among the stores.\n",
        "\n",
        "Overall, these observations provide insights into the factors influencing Rossmann store sales, including promotions, holidays, assortment variety, competition, and day-to-day operations. Understanding these patterns can help in making informed business decisions and optimizing sales strategies."
      ],
      "metadata": {
        "id": "YtK61oLNvWGO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j5SUPF_3S5S"
      },
      "source": [
        "## Model building conclusion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_df = pd.DataFrame({'Train_Score':[train_score1,train_score2,train_score3,train_score4,train_score5,train_score6,train_score7],'Test_Score':[test_score1,test_score2,test_score3,test_score4,test_score5,test_score6, test_score7]},index=['Linear Regression(No Scaling)','Linear Regression(With Scaling)','Lasso Regression','Lasso Regression(hyperparameter Tunning)','Decision Tree',\"Decision Tree(hyperparameter Tunning)\",'Random Forest'])\n",
        "score_df"
      ],
      "metadata": {
        "id": "RD5QZx_49xCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As we can observed from above the random forest ML model as final model as it gives us the maximum accuracy and minimum mean squared error. The training accuracy is 99.63% while the test accuracy is 97.47%. The mean squared error is 0.0046 **"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}